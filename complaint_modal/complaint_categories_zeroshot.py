"""
Complaint extraction using zero-shot classification (BART-large-mnli).
- Optimized for GPU processing with batch support
- Uses GPU if available, falls back to CPU
- Batch processing for 10x+ speed improvement
"""
from transformers import pipeline
import torch
import time

COMPLAINT_LABELS = {
    "material_quality": "Bad material quality, cheap, flimsy, broke, damaged",
    "sound_quality": "Poor sound, muffled, distortion, static, bad audio",
    "battery_life": "Short battery life, battery dies quickly, charging issues",
    "comfort_fit": "Uncomfortable, too tight, too loose, painful to wear",
    "connectivity": "Connection issues, disconnects, lag, pairing problems",
    "shipping_delivery": "Late delivery, damaged packaging, lost item",
    "price_value": "Too expensive, overpriced, not worth the money",
    "customer_service": "Bad customer service, unhelpful, rude, no response"
}

# Detect and configure GPU/CPU device
if torch.cuda.is_available():
    device = 0
    device_name = torch.cuda.get_device_name(0)
    print(f"üöÄ GPU detected: {device_name}")
else:
    device = -1
    print("üíª Using CPU (GPU not available)")

# Global variable to hold the classifier (lazy loading)
zero_shot_classifier = None

def _get_classifier():
    """Lazy load the zero-shot classifier to avoid loading multiple times"""
    global zero_shot_classifier
    if zero_shot_classifier is None:
        print("üî• Loading BART-large-mnli model...")
        start_time = time.time()
        zero_shot_classifier = pipeline(
            "zero-shot-classification",
            model="facebook/bart-large-mnli",
            device=device,
            # Add optimizations
            torch_dtype=torch.float16 if device >= 0 else torch.float32,  # Use half precision on GPU
            return_all_scores=True  # Get all scores for efficiency
        )
        load_time = time.time() - start_time
        print(f"‚úÖ Model loaded in {load_time:.2f} seconds")
    return zero_shot_classifier

def extract_complaints_zeroshot(text, threshold=0.5):
    """
    Use zero-shot classification to extract complaint categories from text.
    Returns a dictionary with complaint categories and their scores.
    """
    classifier = _get_classifier()
    result = classifier(
        text,
        list(COMPLAINT_LABELS.values()),
        multi_label=True
    )
    complaints = {}
    for label, score in zip(result['labels'], result['scores']):
        if score >= threshold:
            # Find the category key by description
            for k, v in COMPLAINT_LABELS.items():
                if v == label:
                    complaints[k] = {'score': float(score), 'description': v}
    return complaints

def extract_complaints_batch(texts, threshold=0.5, batch_size=16):
    """
    Process multiple texts in batches for much faster processing.
    Returns a list of complaint dictionaries for each text.
    """
    if not texts:
        return []
    
    print(f"üî• Processing {len(texts)} texts in batches of {batch_size}...")
    start_time = time.time()
    
    all_complaints = []
    label_values = list(COMPLAINT_LABELS.values())
    
    # Process in batches
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        batch_start = time.time()
        
        try:
            # Process batch all at once
            classifier = _get_classifier()
            results = classifier(
                batch_texts,
                label_values,
                multi_label=True
            )
            
            # Handle single result vs batch results
            if not isinstance(results, list):
                results = [results]
            
            # Process each result in the batch
            batch_complaints = []
            for result in results:
                complaints = {}
                for label, score in zip(result['labels'], result['scores']):
                    if score >= threshold:
                        # Find the category key by description
                        for k, v in COMPLAINT_LABELS.items():
                            if v == label:
                                complaints[k] = {'score': float(score), 'description': v}
                                break
                batch_complaints.append(complaints)
            
            all_complaints.extend(batch_complaints)
            
            batch_time = time.time() - batch_start
            progress = ((i + len(batch_texts)) / len(texts)) * 100
            print(f"üìä Batch {i//batch_size + 1}: {len(batch_texts)} texts processed in {batch_time:.2f}s ({progress:.1f}% complete)")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error processing batch {i//batch_size + 1}: {e}")
            # Add empty results for failed batch
            batch_complaints = [{} for _ in batch_texts]
            all_complaints.extend(batch_complaints)
    
    total_time = time.time() - start_time
    print(f"‚úÖ Batch processing complete! {len(texts)} texts processed in {total_time:.2f} seconds")
    print(f"‚ö° Average: {total_time/len(texts):.3f} seconds per text")
    
    return all_complaints 